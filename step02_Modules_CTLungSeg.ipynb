{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Official Page\n",
    "[Modules — CTLungSeg 2.0.0 documentation (covid-19-ggo-segmentation.readthedocs.io)](https://covid-19-ggo-segmentation.readthedocs.io/en/latest/modules.html)\n",
    "\n",
    "Together with the scripts, a series of modules are provided. Each module contains a series of functions for image processing which are used during the script developing. The modules are the following, each of them provides a different kind of functions."
   ],
   "id": "1dbf60d821177283"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CTLungSeg.utils\n",
    "## Overview\n",
    "这个名为utils.py的文件是一个Python模块，它包含了一些用于处理图像和数据的实用函数。下面是对文件中各部分的解释：\n",
    "\n",
    "- 首先，文件包含了一些导入语句，导入了一些常用的库，如`os`、`pickle`、`SimpleITK`和`numpy`。\n",
    "\n",
    "- 然后，文件定义了一些全局变量，如`__author__`和`__email__`，用于指定作者和电子邮件联系方式。\n",
    "\n",
    "- 接下来，文件定义了一些函数，包括：\n",
    "  - `load_pickle(filename)`：从pickle文件中加载数据。\n",
    "  - `_read_dicom_series(filedir)`：定义并初始化用于读取DICOM系列图像的SimpleITK阅读器。\n",
    "  - `_read_image(filename)`：定义并初始化SimpleITK图像阅读器。\n",
    "  - `read_image(filename)`：从支持的格式中读取图像或系列图像。\n",
    "  - `write_volume(image, output_filename)`：将图像以指定的格式写入文件。\n",
    "  - `save_pickle(filename, data)`：将图像数据保存为pickle文件。\n",
    "  - `normalize(image)`：将图像进行归一化处理。\n",
    "  - `shift_and_crop(image)`：将图像进行平移和裁剪处理。\n",
    "  - `shuffle_and_split(data, number_of_subarrays)`：将输入数据打乱并分成多个子数组。\n",
    "  - `deep_copy(image)`：返回输入图像的副本。\n",
    "\n",
    "每个函数都有详细的文档字符串，描述了函数的参数和返回值，以及函数的使用示例。\n",
    "\n",
    "这个`utils.py`模块提供了一些常用的图像处理功能，可以方便地在其他Python程序中导入和使用。你可以根据需要使用这些函数来加载、保存、处理和分析图像数据。\n",
    "## Related Knowledge\n",
    "### pickle\n",
    "`pickle`是Python标准库中的一个模块，用于序列化（即将对象转换为字节流）和反序列化（即将字节流转换为对象）。它提供了一种简单而强大的方式来将复杂的Python对象转换为可存储或传输的形式。\n",
    "\n",
    "`pickle`模块的主要功能包括：\n",
    "\n",
    "1. 对象的序列化和反序列化：`pickle`模块允许将Python对象序列化为字节流，以便在存储或传输时使用。通过`pickle.dump()`函数可以将对象序列化到文件中，而`pickle.dumps()`函数则返回字节流的表示。反之，可以使用`pickle.load()`函数从文件中反序列化对象，或者使用`pickle.loads()`函数从字节流中反序列化对象。\n",
    "\n",
    "2. 支持多种Python对象：`pickle`模块可以处理几乎所有的Python对象，包括数字、字符串、列表、元组、字典、自定义类的实例等等。它甚至可以处理循环引用和共享引用的对象。\n",
    "\n",
    "3. 保持对象的结构：序列化后的对象可以还原为原始对象的完整结构，包括对象的层次结构、属性和方法等。\n",
    "\n",
    "需要注意的是，`pickle`模块生成的字节流是Python特定的，因此只能在Python环境中使用。如果需要与其他编程语言进行交互，可以考虑使用通用的序列化格式，如JSON或MessagePack。\n",
    "\n",
    "以下是一个简单的示例，演示了如何使用`pickle`模块将对象序列化和反序列化：\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# 序列化对象\n",
    "data = [1, 2, 3, 4, 5]\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# 反序列化对象\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "print(loaded_data)  # 输出: [1, 2, 3, 4, 5]\n",
    "```\n",
    "\n",
    "在这个示例中，我们首先将一个列表对象`data`序列化到文件`data.pickle`中，然后再从文件中反序列化出一个新的列表`loaded_data`。最后，将`loaded_data`打印出来，可以看到它与原始的`data`列表是相同的。\n",
    "\n",
    "`pickle`模块在许多场景中都很有用，例如在机器学习中保存和加载训练好的模型、在分布式系统中传输和共享数据等。但需要注意的是，由于`pickle`可以执行任意的Python代码，因此在从不受信任的源加载`pickle`数据时要格外小心，以防止安全风险。\n",
    "### sitk.ImageSeriesReader()\n",
    "`SimpleITK.ImageSeriesReader()`是SimpleITK库中的一个类，用于读取DICOM图像系列（DICOM Series）。\n",
    "\n",
    "DICOM图像通常由一系列的DICOM文件组成，每个文件对应一个图像切片。`ImageSeriesReader`类提供了一种方便的方式来读取和处理这些DICOM图像系列。\n",
    "\n",
    "以下是`ImageSeriesReader`类的一些重要特征和用法：\n",
    "\n",
    "1. 构造函数：`ImageSeriesReader`类的构造函数可以接受一个可选的参数`imageIO`，用于指定用于读取DICOM文件的ImageIO实例。如果未指定，则会使用默认的ImageIO实例。\n",
    "\n",
    "2. `SetFileNames()`方法：通过调用`SetFileNames()`方法，可以将DICOM图像系列的文件名列表传递给`ImageSeriesReader`对象。文件名列表应按照DICOM图像的切片顺序排列。\n",
    "\n",
    "3. `Execute()`方法：一旦设置了文件名列表，可以调用`Execute()`方法来读取DICOM图像系列。该方法会自动识别并读取整个系列，并返回一个SimpleITK图像对象。\n",
    "\n",
    "4. `GetGantryAngle()`和`GetPatientPosition()`等方法：`ImageSeriesReader`类还提供了一些方法用于获取DICOM图像系列中的元数据信息，如旋转角度、患者位置等。\n",
    "\n",
    "下面是一个简单的示例，演示了如何使用`ImageSeriesReader`类读取DICOM图像系列：\n",
    "\n",
    "```python\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# 创建 ImageSeriesReader 实例\n",
    "reader = sitk.ImageSeriesReader()\n",
    "\n",
    "# 设置 DICOM 图像系列的文件名列表\n",
    "series_file_names = sitk.ImageSeriesReader.GetGDCMSeriesFileNames('path/to/dicom_dir')\n",
    "reader.SetFileNames(series_file_names)\n",
    "\n",
    "# 读取 DICOM 图像系列\n",
    "image = reader.Execute()\n",
    "\n",
    "# 获取图像的旋转角度\n",
    "gantry_angle = reader.GetGantryAngle()\n",
    "\n",
    "# 获取患者位置\n",
    "patient_position = reader.GetPatientPosition()\n",
    "\n",
    "# 打印图像信息\n",
    "print(\"Image size:\", image.GetSize())\n",
    "print(\"Gantry angle:\", gantry_angle)\n",
    "print(\"Patient position:\", patient_position)\n",
    "```\n",
    "\n",
    "在这个示例中，我们首先创建了一个`ImageSeriesReader`对象，然后通过调用`SetFileNames()`方法将DICOM图像系列的文件名列表传递给对象。接下来，调用`Execute()`方法读取整个系列，并将结果保存在`image`变量中。最后，使用`GetGantryAngle()`和`GetPatientPosition()`等方法获取图像的旋转角度和患者位置，并将其打印出来。\n",
    "\n",
    "使用`ImageSeriesReader`类可以方便地读取DICOM图像系列，并进行后续的图像处理和分析。\n",
    "### normalize(归一化)\n",
    "在计算机影像中，归一化（Normalization）是一种常见的图像预处理技术，其主要作用是将图像的像素值范围映射到特定的区间，以便更好地适应后续的图像处理和分析任务。\n",
    "\n",
    "归一化的作用包括：\n",
    "\n",
    "1. 增强对比度：通过将像素值重新映射到较大的值域，归一化可以增强图像的对比度。这有助于提升图像的视觉可辨度和细节信息。\n",
    "\n",
    "2. 消除光照变化：归一化可以抵消图像中的光照变化。例如，在图像中存在明暗不均匀的光照条件下，归一化可以将光照变化的影响降低，使得图像更加一致，便于后续的分析和处理。\n",
    "\n",
    "3. 提供统一的尺度：不同图像的像素值范围可能不同，归一化可以将它们映射到相同的尺度，以便进行比较和处理。例如，在机器学习中，归一化可以确保不同图像的特征具有相似的数值范围，从而避免某些特征对模型训练的影响过大。\n",
    "\n",
    "4. 去除噪声和异常值的影响：通过归一化图像，可以减小噪声和异常值对图像处理和分析的影响。归一化可以使得图像中的噪声和异常值在整个像素值范围内分布均匀，而不会偏离过远。\n",
    "\n",
    "常见的归一化方法包括线性归一化（Min-Max Scaling）、Z-score归一化等。具体的归一化方法选择取决于数据的特性和任务的需求。\n",
    "\n",
    "总之，归一化在计算机影像中可以提升图像质量、减少噪声和异常值的影响，并为后续的图像处理和分析提供更好的基础。\n",
    "### GL(Gray Level)\n",
    "\"GL\" 是 \"灰度级\"（Gray Level）的缩写。在图像处理和分析中，灰度级指的是图像中每个像素的灰度值。灰度值通常表示为一个范围内的整数或浮点数，用于表示像素的亮度或颜色强度。\n",
    "\n",
    "对于灰度图像，每个像素只有一个灰度级，表示图像在该像素位置的亮度或灰度强度。灰度级的范围通常是 0 到 255 或 0 到 1，取决于图像的数据类型。较低的灰度级表示较暗的像素，而较高的灰度级表示较亮的像素。\n",
    "\n",
    "在 `normalize(image)` 函数中，通过计算整个图像的均值和标准差来对图像进行标准化。这样可以将图像的灰度级重新缩放，以便不同图像的灰度值范围保持一致，从而更好地适应后续的图像处理和分析任务。\n",
    "### HU(Hounsfiled Unit)\n",
    "[Wikipedia:Hounsfiled Unit](https://zh.wikipedia.org/wiki/%E4%BA%A8%E6%B0%8F%E5%96%AE%E4%BD%8D)\n",
    "\n",
    "医学上HU介于[-1000,+1000],其中-1000(air),+1000(致密骨),0(水)"
   ],
   "id": "51c58c94eaf706e0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# utils\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def _load_pickle(path):\n",
    "    \"\"\"读取pickle文件(持续化存储文件)\"\"\"\n",
    "    with open(path, 'rb') as f:  # with as语句自动抛出异常和关闭文件\n",
    "        data = np.load(f, allow_pickle=True)\n",
    "    return data\n",
    "\n",
    "def _read_image_series(path):\n",
    "    \"\"\"定义ImageSeries读取器 \"\"\"\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    names = reader.GetGDCMSeriesFileNames(path)  # 设置读取文件序列名为源文件名\n",
    "    reader.SetFileNames(names)\n",
    "    return reader\n",
    "\n",
    "def _read_image(path):\n",
    "    \"\"\"定义ImageFile读取器\"\"\"\n",
    "    reader = sitk.ImageFileReader()\n",
    "    reader.SetFileName(path)\n",
    "    return reader\n",
    "\n",
    "def read_image(path):\n",
    "    \"\"\"读取path下Image Series/File\"\"\"\n",
    "    if os.path.exists(path):  # 如果路径存在\n",
    "        if os.path.isfile(path):  # 路径下是文件,调用ImageFile读取器\n",
    "            reader = _read_image(path)\n",
    "        else:  # 路径下是文件夹,调用ImageSeries读取器\n",
    "            reader = _read_image_series(path)\n",
    "        \n",
    "        image = reader.Execute()  # 执行图像读取操作\n",
    "    else:  # 路径不存在抛出异常\n",
    "        raise FileNotFoundError(f\"Cannot find {path}\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "def write_image(image, filename):\n",
    "    \"\"\"保存图像文件(nrrd/nii)\"\"\"\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.SetFileName(filename)\n",
    "    writer.Execute(image)\n",
    "\n",
    "def save_pickle(path, data):\n",
    "    \"\"\"将image保存为pickle格式文件\"\"\"\n",
    "    with open(path, 'wb') as f: \n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"图像归一化\"\"\"\n",
    "    statistics = sitk.StatisticsImageFilter()  # 实例化图像统计信息计算器\n",
    "    statistics.Execute(image)  # 计算图像统计信息,并存放于计算器实例化对象statistics中\n",
    "    \n",
    "    if np.isclose(statistics.GetSigma(), 0):  # 计算图像标准差是否接近0(常值/单色图像)\n",
    "        raise ZeroDivisionError('Cannot normalize image with zero sigma')\n",
    "    \n",
    "    normalizer = sitk.NormalizeImageFilter()  # 实例化归一化过滤器\n",
    "    return normalizer.Execute(image)  # 返回归一化后image\n",
    "\n",
    "def shift_and_threshold(image):\n",
    "    \"\"\"将HU值整体平移(shift)直至下限为0,再将峰值大于+2048的部分截断(threshold)\"\"\"\n",
    "    image_shift = sitk.ShiftScale(image, 1000, 1.0)  # 1000:偏移量,1.0:缩放比例\n",
    "    image_shift_and_threshold = sitk.Threshold(image1=image_shift, lower=0, upper=2048, outsideValue=0)  # outsideValue表示范围外数据赋值\n",
    "    return image_shift_and_threshold\n",
    "    # return sitk.Threshold(image1=sitk.ShiftScale(image, 1000, 1.0), lower=0, upper=2048, outsideValue=0)\n",
    "\n",
    "def shuffle_and_split(data, num_of_subarrays):\n",
    "    \"\"\"打乱并分组\"\"\"\n",
    "    np.random.shuffle(data)  # 打乱\n",
    "    array_list = np.array_split(data, num_of_subarrays)  # 返回子数组列表,包含划分后的子数组,每个子数组都是NumPy数组对象\n",
    "    return np.array(array_list, dtype=np.ndarray)  # 将子数组列表array_list转换为np数组,并使用dtype=np.ndarray指定数组的数据类型为ndarray,确保返回的每个子数组都是np数组对象\n",
    "\n",
    "def deep_copy(image):\n",
    "    \"\"\"医学图像复制\"\"\"\n",
    "    copy_np = sitk.GetArrayFromImage(image).copy()  # 通过sitk将医学图像读取为np格式,读取其副本到copy_np\n",
    "    copy_image = sitk.GetImageFromArray(copy_np)  # 通过sitk将np读取为医学图像格式\n",
    "    copy_image.CopyInformation(image)  # 将原image的元数据(meta-data)(原点、方向、间距等)复制到copy\n",
    "    return copy_image\n",
    "    "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CTLungSeg.methods\n",
    "## Overview\n",
    "这是一个名为`method.py`的Python文件，它包含了一些用于图像处理的方法和函数。让我来逐行解释每个部分的含义：\n",
    "\n",
    "- `import SimpleITK as sitk`：这行代码导入了名为SimpleITK的Python库，并将其命名为`sitk`，以便在后续的代码中使用。\n",
    "\n",
    "- `bounding_values` 和 `image_types`：这两个变量是字典，用于存储不同数据类型的图像的边界值和对应的SimpleITK数据类型。这些信息在后续的函数中用到。\n",
    "\n",
    "- `median_filter`、`std_filter`、`gauss_smooth`、`adaptive_histogram_equalization`、`adjust_gamma`、`apply_mask`、`vesselness`、`threshold`、`cast_image`：这些是用于图像处理的函数，每个函数都有特定的功能和参数说明。可以根据需要调用这些函数来进行相应的图像处理操作。\n",
    "\n",
    "该文件提供了一些常见的图像处理功能，例如中值滤波、标准差滤波、高斯平滑、自适应直方图均衡化、伽马校正、应用掩膜、血管性等等。每个函数都有相应的参数和用法示例。\n",
    "## Related Knowledge\n",
    "### Median Filter(中值滤波)\n",
    "[link](https://blog.csdn.net/weixin_51571728/article/details/121545254)\n",
    "\n",
    "中值滤波（Median Filtering）是一种常用的图像处理技术，用于去除图像中的噪声。它通过将每个像素替换为其邻域内像素值的中值来实现去噪的效果。\n",
    "\n",
    "中值滤波的基本思想是对图像中的每个像素，定义一个邻域，通常是以该像素为中心的一个正方形或圆形区域。然后，将邻域内的像素值进行排序，选取排序后的中间值作为中心像素的新值。\n",
    "\n",
    "具体步骤如下：\n",
    "\n",
    "1. 对图像中的每个像素，定义一个邻域，包含该像素及其周围的像素。\n",
    "\n",
    "2. 将邻域内的像素值进行排序，从小到大排列。\n",
    "\n",
    "3. 选取排序后的中间值作为中心像素的新值。\n",
    "\n",
    "4. 重复以上步骤，处理图像中的每个像素。\n",
    "\n",
    "中值滤波的优点是能够有效地去除各种类型的噪声，包括椒盐噪声和高斯噪声等。相比于其他平滑滤波器（如均值滤波器），中值滤波能够更好地保留图像的边缘和细节信息，因为它不受异常值的影响。\n",
    "\n",
    "然而，中值滤波也存在一些缺点。较大的邻域大小可能会导致图像细节的模糊化，因为中值滤波将图像中的每个像素都替换为邻域内的中值。此外，中值滤波在处理某些类型的噪声时可能会产生一些不理想的效果。\n",
    "\n",
    "因此，在应用中值滤波时，需要根据具体的图像和噪声情况选择合适的邻域大小，以平衡去噪效果和细节保留的需求。\n",
    "### Standard Deviation Filter(标准差滤波)\n",
    "标准差滤波（Standard Deviation Filtering）是一种常用的图像处理技术，用于平滑图像、减少噪声或突出图像中的某些特征。它基于图像中像素值的统计特性，通过计算邻域内像素值的标准差来调整像素的值。\n",
    "\n",
    "标准差是一种衡量数据分散程度的统计指标。在图像处理中，可以将标准差看作是邻域内像素值的变化程度的度量。较大的标准差表示像素值的变化较大，而较小的标准差表示像素值的变化较小。\n",
    "\n",
    "标准差滤波的基本思想是对图像中的每个像素，计算其周围邻域内像素值的标准差，并用该标准差值来调整像素的值。具体步骤如下：\n",
    "\n",
    "1. 对图像中的每个像素，定义一个邻域，通常是以该像素为中心的一个正方形或圆形区域。\n",
    "\n",
    "2. 在邻域内计算像素值的标准差，标准差越大表示该邻域内的像素值变化越大。\n",
    "\n",
    "3. 将中心像素的值替换为邻域内像素值的标准差。\n",
    "\n",
    "通过这种方式，标准差滤波可以实现对图像的平滑操作。当邻域内的像素值变化较大时，中心像素的值将被调整为较大的标准差，从而减少噪声或突出图像中的边缘和纹理等特征。\n",
    "\n",
    "需要注意的是，标准差滤波可能会导致图像的平滑效果，从而使一些细节信息模糊化。因此，在应用标准差滤波时需要根据具体应用场景和需求来选择合适的邻域大小和滤波参数。\n",
    "### Gaussian Smoothing/Filter(高斯平滑/滤波)\n",
    "高斯平滑和高斯滤波是两个相关但不完全相同的概念。\n",
    "\n",
    "高斯平滑（Gaussian Smoothing）是一种图像处理技术，用于减少图像中的噪声并平滑图像。它基于高斯函数的概念，通过在图像上应用高斯滤波器来实现。高斯函数是一种钟形曲线，可以根据指定的标准差来调整曲线的形状。\n",
    "\n",
    "高斯滤波（Gaussian Filtering）是一种滤波器，在高斯滤波中，对于图像中的每个像素，通过与周围像素的加权平均值进行卷积来计算新的像素值。权重是根据高斯函数计算的，与像素之间的距离和标准差有关。具体而言，离中心点越远的像素的权重越小，离中心点越近的像素的权重越大。高斯滤波器的目的是模糊图像并减少噪声。\n",
    "\n",
    "高斯滤波在图像处理中有许多应用，包括：\n",
    "\n",
    "- 平滑图像以减少噪声。\n",
    "- 提取图像中的边缘信息。\n",
    "- 减少图像中的细节和纹理。\n",
    "- 在图像处理前的预处理步骤中使用，如图像分割、特征提取等\n",
    "\n",
    "因此，可以说高斯平滑是通过应用高斯滤波器来实现的一种图像平滑技术。高斯滤波是一种特定的滤波器，它使用高斯函数来计算像素之间的加权平均值。\n",
    "\n",
    "两者的区别在于应用的角度和概念上的差异。高斯平滑是一种图像处理技术，描述了通过高斯滤波器对图像进行平滑的过程。而高斯滤波是具体的滤波器，描述了通过应用高斯函数来计算像素加权平均值的过程。\n",
    "\n",
    "总结起来，高斯平滑是一种图像平滑的方法，而高斯滤波是一种实现高斯平滑的具体滤波器。\n",
    "#### sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "`sitk.SmoothingRecursiveGaussianImageFilter`是SimpleITK库中的一个滤波器，用于对图像进行平滑处理。它采用了递归高斯滤波算法，能够在保持较高滤波效果的同时，实现较快的计算速度。\n",
    "\n",
    "`sitk.SmoothingRecursiveGaussianImageFilter`的一些重要属性和方法包括：\n",
    "\n",
    "- `SetSigma(sigma)`：设置高斯滤波器的标准差。标准差值越大，平滑效果越明显。\n",
    "- `SetNormalizeAcrossScale(normalize)`：设置是否在不同尺度上进行归一化处理。默认情况下，会对不同尺度的滤波结果进行归一化，以保持图像的亮度和对比度。\n",
    "- `SetNumberOfRecursiveIterations(iterations)`：设置递归迭代的次数。迭代次数越多，平滑效果越明显。\n",
    "- `Execute(image)`：将滤波器应用于输入图像，并返回平滑后的图像。\n",
    "\n",
    "使用`sitk.SmoothingRecursiveGaussianImageFilter`，您可以根据需要对图像进行平滑处理。通过调整标准差、归一化设置和迭代次数等参数，可以控制平滑效果和计算速度。\n",
    "\n",
    "以下是一个示例代码，演示如何使用`sitk.SmoothingRecursiveGaussianImageFilter`对图像进行平滑处理：\n",
    "\n",
    "```python\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# 读取输入图像\n",
    "input_image = sitk.ReadImage(\"input_image.jpg\")\n",
    "\n",
    "# 创建平滑滤波器实例\n",
    "smoothing_filter = sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "smoothing_filter.SetSigma(2.0)\n",
    "smoothing_filter.SetNormalizeAcrossScale(True)\n",
    "smoothing_filter.SetNumberOfRecursiveIterations(5)\n",
    "\n",
    "# 应用平滑滤波器到图像\n",
    "smoothed_image = smoothing_filter.Execute(input_image)\n",
    "\n",
    "# 保存平滑后的图像\n",
    "sitk.WriteImage(smoothed_image, \"smoothed_image.jpg\")\n",
    "```\n",
    "### Adaptive Histogram Equalization(自适应直方图均衡化)\n",
    "自适应直方图均衡化（Adaptive Histogram Equalization）是一种用于增强图像对比度的图像处理技术。与传统的全局直方图均衡化相比，自适应直方图均衡化可以根据图像的局部区域进行对比度增强，从而更好地处理具有不均匀光照条件的图像。\n",
    "\n",
    "在自适应直方图均衡化中，图像被分割成多个重叠的小区域，然后在每个小区域内进行局部直方图均衡化。这样可以保留图像的局部细节，并避免全局均衡化导致的过度增强。\n",
    "\n",
    "以下是一种常见的自适应直方图均衡化方法，称为自适应直方图均衡化（AHE）：\n",
    "1. 将图像分割成小的重叠区域或网格。\n",
    "2. 对于每个区域，计算该区域内的直方图。\n",
    "3. 对于每个区域，应用直方图均衡化以增强对比度。\n",
    "4. 将各个区域的结果合并以得到最终的均衡化图像。\n",
    "\n",
    "自适应直方图均衡化可以通过不同的方法实现，包括基于局部直方图的传统方法和基于块的方法，如自适应直方图均衡化（CLAHE）。\n",
    "\n",
    "自适应直方图均衡化在许多图像处理应用中都有广泛的应用，特别是在医学图像处理中，用于增强医学图像中的细节和改善对比度。\n",
    "#### itk.AdaptiveHistogramEqualizationImageFilter()\n",
    "[Official Document](https://examples.itk.org/src/filtering/imagestatistics/adaptivehistogramequalizationimagefilter/documentation)\n",
    "- Alpha参数：Alpha参数控制对比度增强的程度。较大的Alpha值会产生更强烈的对比度增强效果，使图像中的细节更加明显。然而，过大的Alpha值可能会导致图像出现过度增强的情况。通常，Alpha的取值范围为0到1之间，默认值为0.5。\n",
    "- Beta参数：Beta参数用于控制直方图均衡化的过程。较小的Beta值会产生较平坦的直方图，从而增强图像的整体对比度。而较大的Beta值会保留更多的原始直方图特征，以更好地保持图像的整体分布。Beta的取值范围为0到1之间，默认值为0.5。\n",
    "- \n",
    "在ITK中，`itk.AdaptiveHistogramEqualizationImageFilter`是一个用于自适应直方图均衡化的滤波器。自适应直方图均衡化（Adaptive Histogram Equalization，AHE）是一种用于增强图像对比度的方法，它在不同区域内分别应用直方图均衡化，以提高局部细节的可见性。\n",
    "\n",
    "`itk.AdaptiveHistogramEqualizationImageFilter`的作用是对输入图像进行自适应直方图均衡化，并生成增强对比度的输出图像。它基于图像中的局部块，计算每个块的局部直方图，并将每个块内的像素值映射到均衡化后的像素值。\n",
    "\n",
    "以下是一个使用`itk.AdaptiveHistogramEqualizationImageFilter`的简单示例：\n",
    "\n",
    "```python\n",
    "import itk\n",
    "\n",
    "# 读取输入图像\n",
    "input_image = itk.imread(\"input_image.jpg\")\n",
    "\n",
    "# 创建滤波器对象\n",
    "filter = itk.AdaptiveHistogramEqualizationImageFilter.New()\n",
    "filter.SetInput(input_image)\n",
    "\n",
    "# 设置滤波器参数\n",
    "filter.SetRadius(8)  # 指定块的半径\n",
    "filter.SetAlpha(0.5)  # 控制对比度增强的参数\n",
    "\n",
    "# 执行滤波器\n",
    "filter.Update()\n",
    "\n",
    "# 获取输出图像\n",
    "output_image = filter.GetOutput()\n",
    "\n",
    "# 保存输出图像\n",
    "itk.imwrite(output_image, \"output_image.jpg\")\n",
    "```\n",
    "\n",
    "在上述示例中，我们首先使用`itk.imread`函数读取输入图像。然后，我们创建了`itk.AdaptiveHistogramEqualizationImageFilter`的实例，并将输入图像设置为滤波器的输入。接下来，我们可以通过设置滤波器的参数来调整块的大小和对比度增强的程度。最后，我们使用`itk.imwrite`函数保存输出图像。\n",
    "\n",
    "请注意，这只是一个简单的示例，您可以根据需要进一步探索和调整`itk.AdaptiveHistogramEqualizationImageFilter`的参数和用法。\n",
    "### Gamma Correction(伽马校正)\n",
    "伽马校正（Gamma correction）是一种非线性的图像处理技术，用于调整图像的对比度和亮度。它通过对图像中的像素值进行幂次变换来改变图像的显示效果。\n",
    "\n",
    "在计算机图形学和数字图像处理中，人眼对亮度的感知是非线性的。在显示设备（如计算机显示器）中，像素的输出亮度与输入信号之间存在一种非线性关系。伽马校正通过将输入图像的每个像素值进行幂次变换，以模拟显示设备的非线性响应，从而使图像在显示时更符合人眼对亮度的感知。\n",
    "\n",
    "伽马校正的数学表达式如下：\n",
    "$$GL_{out} = GL_{in}^{\\gamma}$$\n",
    "其中，`GL_in`是输入图像的像素值，`GL_out`是校正后的像素值，`γ`是校正参数（也称为伽马值）。通过调整伽马值，可以改变图像的对比度和亮度。\n",
    "\n",
    "具体来说，当伽马值小于1时，校正后的图像会增加高亮度部分的对比度，使其更清晰明亮。而当伽马值大于1时，校正后的图像会增加低亮度部分的对比度，使其更丰富和饱和。当伽马值等于1时，表示不进行任何校正，图像保持不变。\n",
    "\n",
    "伽马校正广泛应用于图像处理、计算机图形学、数字摄影等领域。在实际应用中，常见的用途包括：\n",
    "- 显示设备的校正：将图像在不同显示设备上显示时的亮度差异进行校正，使其更符合人眼感知。\n",
    "- 图像增强：通过调整伽马值来增强图像的对比度和细节，使图像更清晰和易于分析。\n",
    "- 图像压缩：在某些图像压缩算法中，使用伽马校正来调整图像的动态范围，以提高压缩效率。\n",
    "\n",
    "总之，伽马校正是一种常用的图像处理技术，通过对图像的像素值进行幂次变换，调整图像的对比度和亮度，以获得更好的视觉效果和人眼感知。\n",
    "### Interval Threshold(区间阈值分割)\n",
    "区间阈值（Interval Threshold）是一种图像分割方法，用于将图像中的像素根据其灰度值范围进行分类。它通过定义上下阈值来确定一个灰度值的区间，将位于该区间内的像素标记为前景或感兴趣区域，而将位于区间外的像素标记为背景或非感兴趣区域。\n",
    "\n",
    "区间阈值分割常用于将图像中的目标或特定结构从其背景中分离出来。例如，在医学影像中，区间阈值分割可以用于提取肿瘤、血管或其他感兴趣的解剖结构。\n",
    "\n",
    "区间阈值方法的基本原理是通过设置上下阈值来定义一个灰度值的范围，该范围内的像素被视为目标或感兴趣区域，而范围外的像素被视为背景或非感兴趣区域。在分割过程中，像素的灰度值与预先定义的阈值进行比较，并根据比较结果进行分类。"
   ],
   "id": "c23ffa5fda3471be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:28:08.215012Z",
     "start_time": "2024-05-04T15:28:01.892274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# method\n",
    "import SimpleITK as sitk\n",
    "\n",
    "def median_filter(image, radius):\n",
    "    \"\"\"中值滤波,去除椒盐噪音\"\"\"\n",
    "    if radius <= 0:\n",
    "        raise ValueError('radius must be greater or equal than 1')\n",
    "    filter = sitk.MedianImageFilter()\n",
    "    filter.SetRadius(int(radius))  # 设置kernel_size=3\n",
    "    return filter.Execute(image)\n",
    "\n",
    "def std_filter(image, radius):\n",
    "    \"\"\"标准差滤波,平滑图像\"\"\"\n",
    "    if radius <= 0:\n",
    "        raise ValueError('radius must be greater or equal than 1')\n",
    "    filter = sitk.NoiseImageFilter()\n",
    "    filter.SetRadius(int(radius))\n",
    "    return filter.Execute(image)\n",
    "\n",
    "def gaussian_filter(image, sigma = 1.):\n",
    "    \"\"\"高斯滤波,模糊/平滑图像\"\"\"\n",
    "    filter = sitk.SmoothingRecursiveGaussianImageFilter()\n",
    "    filter.SetSigma(sigma)\n",
    "    return filter.Execute(image)\n",
    "\n",
    "def adaptive_histogram_equalization(image, radius):\n",
    "    \"\"\"自适应直方图均衡化\"\"\"\n",
    "    filter = sitk.AdaptiveHistogramEqualizationImageFilter()\n",
    "    filter.SetAlpha(1)\n",
    "    filter.SetBeta(1)\n",
    "    filter.SetRadius(radius)\n",
    "    return filter.Execute(image)\n",
    "\n",
    "def cast_image(image, target_type):\n",
    "    \"\"\"图像类型转换\"\"\"\n",
    "    caster = sitk.CastImageFilter()\n",
    "    caster.SetOutputPixelType(target_type)\n",
    "    return caster.Execute(image)\n",
    "\n",
    "\n",
    "def gamma_correction(image, gamma=1.0, image_type='HU'):\n",
    "    \"\"\"伽马校正\"\"\"\n",
    "    bounding_values = {'uint8' : [0, 255],\n",
    "                       'uint16': [0, 2**16],\n",
    "                       'HU' : [0, 2**12]}\n",
    "    image_types = {'uint8' : sitk.sitkUInt8,\n",
    "                   'uint16': sitk.sitkUInt16,\n",
    "                   'HU' : sitk.sitkUInt16 }\n",
    "    if gamma == 0:\n",
    "        raise Exception('gamma value cannot be zero')\n",
    "    if image_type not in ['uint8','uint16','HU']:  \n",
    "        raise Exception('image type {} not supported'.format(image_type))\n",
    "    \n",
    "    image = cast_image(image, sitk.sitkFloat32)  # 图像类型转换\n",
    "    # image = sitk.Cast(image, sitk.sitkFloat32)  # 与cast_image中sitk.CastImageFilter().Execute()作用相同\n",
    "    power_filter = sitk.PowImageFilter()  # 实例化幂次变换\n",
    "    inverse_gamma = 1.0 / gamma  # gamma倒数\n",
    "    output = power_filter.Execute(image, inverse_gamma)  # 基于伽马校正公式进行幂次变换\n",
    "    \n",
    "    cur_bound = bounding_values[image_type]  # 根据预设字典按照输入的image_type获取其类型的临界值\n",
    "    out = sitk.Threshold(image1=output, lower=cur_bound[0], upper=cur_bound[1], outsideValue=cur_bound[1])  # 阈值化,下界为阈值下限,上界为阈值上限,界外值设置为阈值上限,饱和了超出指定范围的像素值\n",
    "    \n",
    "    out = sitk.Cast(out, image_types[image_type])  # 图像转换为原类型\n",
    "    return out\n",
    "\n",
    "def apply_mask(image, mask, masking_value=0, outside_value=-1500):\n",
    "    \"\"\"掩膜覆盖\"\"\"\n",
    "    mask_filter = sitk.MaskImageFilter()\n",
    "    mask_filter.SetMaskingValue(masking_value)  # 设定掩膜区域值\n",
    "    mask_filter.SetOutsideValue(outside_value)  # 设定非掩膜区域值\n",
    "    return mask_filter.Execute(image, mask)\n",
    "\n",
    "def find_vessel(image):\n",
    "    \"\"\"寻找血管(一维)\"\"\"\n",
    "    vessel = sitk.ObjectnessMeasureImageFilter()  # 实例化滤波器\n",
    "    vessel.SetObjectDimension(1)  # 设置目标维度为1维\n",
    "    return vessel.Execute(image)\n",
    "\n",
    "def threshold(image, upper, lower, inside=1, outside=0):\n",
    "    \"\"\"区间阈值(interval threshold)\"\"\"\n",
    "    filter = sitk.BinaryThresholdImageFilter()\n",
    "    filter.SetLowerThreshold(lower)\n",
    "    filter.SetUpperThreshold(upper)\n",
    "    filter.SetInsideValue(inside)\n",
    "    filter.SetOutsideValue(outside)\n",
    "    return filter.Execute(image)"
   ],
   "id": "74fdb8367b3d0d52",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CTLungSeg.segmentation\n",
    "## Overview\n",
    "这段代码是一个名为`segmentation`的Python模块文件。我将逐行解释代码的功能和用法。\n",
    "\n",
    "1. 导入了一些需要用到的库，如cv2（OpenCV），numpy和tqdm。\n",
    "\n",
    "2. 定义了三个函数`remove_vessels`，`imlabeling`和`kmeans_on_subsamples`。\n",
    "\n",
    "    - `remove_vessels`函数用于去除图像中的血管。它接受一个输入图像`image`，通过应用高斯平滑和血管性度量计算，生成一个二值掩膜（mask）。最后，使用生成的掩膜将图像中的血管部分置为指定的外部值（-1000），返回处理后的图像`wo_vessels`。\n",
    "    - `imlabeling`函数用于对多通道图像进行标记。它接受一个图像栈`image`和一个中心点向量`centroids`作为参数。如果提供了`weight`参数，则还接受一个权重数组，用于指定在标记过程中要排除的像素。函数根据提供的权重数组或图像计算像素与中心点之间的距离，并将标记结果返回。\n",
    "    - `kmeans_on_subsamples`函数用于在图像的子样本上应用K均值聚类。它接受一个图像张量`imgs`，指定要找到的聚类中心数`n_centroids`，迭代终止条件`stopping_criteria`，以及聚类中心的初始化方法`centr_init`。如果`weight`参数设置为True，则允许在分割过程中排除某些像素。函数将图像张量转换为向量，并在每个子样本上应用K均值聚类。函数返回每个子样本的平方距离之和向量`retval`和每个子样本的聚类中心数组`centroids`。\n",
    "\n",
    "3. 定义了两个作者和邮箱的元数据。\n",
    "\n",
    "4. 这段代码似乎是一个模块文件，提供了一些函数供其他程序使用。它还提供了一些示例用法和示例代码。\n",
    "\n",
    "## Related Knowledge\n",
    "### 欧氏距离计算\n",
    "```python\n",
    "distances = np.asarray([np.linalg.norm(image[weight != 0] -c, axis = 1) for c in centroids])\n",
    "```\n",
    "这行代码使用 NumPy 的函数和方法计算了每个质心和非零权重像素之间的欧氏距离。\n",
    "\n",
    "让我逐步解释这段代码的含义：\n",
    "\n",
    "1. `image[weight != 0]`: 这部分代码使用布尔索引，选择了权重非零的像素。假设 `image` 是一个图像数组，`weight` 是一个与 `image` 相同形状的数组，表示每个像素的权重。通过 `weight != 0`，我们得到一个布尔数组，其中 `True` 表示对应位置上的像素具有非零权重。然后，通过将这个布尔数组应用于 `image`，我们选择了具有非零权重的像素，形成一个一维数组。\n",
    "\n",
    "2. `np.linalg.norm(image[weight != 0] - c, axis=1)`: 这部分代码计算了每个质心 `c` 与选定像素之间的欧氏距离。`np.linalg.norm` 是 NumPy 提供的函数，用于计算向量的范数。`image[weight != 0] - c` 表示将质心 `c` 从选定像素数组中的每个像素中减去，得到一个二维数组。通过将 `axis=1` 参数传递给 `np.linalg.norm`，我们计算了每个行向量的范数，即每个质心与选定像素之间的欧氏距离。这将得到一个一维数组，其中每个元素表示对应质心与选定像素之间的距离。\n",
    "\n",
    "3. `for c in centroids`: 这部分代码使用了一个循环，遍历了质心数组 `centroids` 中的每个质心。\n",
    "\n",
    "4. `[np.linalg.norm(image[weight != 0] - c, axis=1) for c in centroids]`: 最后，通过列表推导式，我们将每个质心与选定像素之间的欧氏距离计算结果组成一个列表。列表中的每个元素都是一个一维数组，表示对应质心与选定像素之间的距离。\n",
    "\n",
    "最终，通过 `np.asarray` 函数，我们将这个列表转换为一个 NumPy 数组，得到了一个二维数组 `distances`，其中每行表示一个质心与选定像素之间的距离。\n",
    "\n",
    "总结起来，这行代码计算了每个质心和非零权重像素之间的欧氏距离，并将结果存储在一个二维数组 `distances` 中。\n",
    "#### np.linalg.norm()\n",
    "[求范数](https://blog.csdn.net/m0_51816252/article/details/126199555)\n"
   ],
   "id": "ad0db41f55e9a103"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T17:00:00.244232Z",
     "start_time": "2024-05-07T16:59:58.544686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# segmentation\n",
    "import CTLungSeg.method\n",
    "import numpy as np\n",
    "\n",
    "def remove_vessel(image, sigma=2, threshold=8):\n",
    "    \"\"\"移除血管(先高斯平滑)\"\"\"\n",
    "    smooth = CTLungSeg.method.gaussian_filter(image, sigma)\n",
    "    vessel = CTLungSeg.method.find_vessel(smooth)\n",
    "    mask = CTLungSeg.method.threshold(image=vessel, upper=4000, lower=threshold, inside=0, outside=1)\n",
    "    return  CTLungSeg.method.apply_mask(image=image, mask=mask, outside_value=-1000)\n",
    "\n",
    "def image_labeling(image, centroids, weight=None):\n",
    "    \"\"\"\n",
    "    图像打标\n",
    "    :param image:array-like of shape (n_images, height, width, n_channels)\n",
    "    :param centroids:array-like of shape (n_centroids, n_channels)\n",
    "    :param weight: array-like of shape (n_images, height, weight)\n",
    "    \"\"\"\n",
    "    # 检查images和centroids的n_channels维度是否相等\n",
    "    if centroids.shape[1] != image.shape[-1]:\n",
    "        raise Exception(\"Numbers of images' channels dose not match the numbers of centroids features : {} != {}\".format(centroids.shape[1],image.shape[-1]))\n",
    "    if weight is not None:\n",
    "        # 检查images和weight的n_images,height,width维度是否相等\n",
    "        if weight.shape != image.shape[:-1]:\n",
    "            raise Exception(\"Weight's shape of [n_images, height, width] dose not match the image's\".format(weight.shape, image.shape[:-1]))\n",
    "        \n",
    "        distances = np.asarray(np.linalg.norm(image[weight != 0] - c, axis=1) for c in centroids)\n",
    "        weight[weight != 0] = np.argmin(distances, axis=0)\n",
    "        return weight\n",
    "    else:\n",
    "        distances = np.asarray([np.linalg.norm(image - c, axis=3) for c in centroids])\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        return labels\n",
    "\n",
    "def kmeans_on_subsamples(image, n_centroids, stopping_criteria, centroids_initiation, weight=False):\n",
    "    \"\"\"\n",
    "    进行聚类分析,并返回聚类结果和质心\n",
    "    \n",
    "    Apply the k-means clustering on each stack of images in the subsample.\n",
    "    Allow also to choose if consider or not some voxel during the segmentation.\n",
    "    To allow these features raise the flag 'weight' and provide as the\n",
    "    last channel a binary mask with 0 on each voxel you want to exclude\n",
    "    \n",
    "    :param image:array-like of shape (n_images, height, width, n_channels) \n",
    "    :param n_centroids: \n",
    "    :param stopping_criteria: \n",
    "    :param centroids_initiation: \n",
    "    :param weight:默认False,在需要考虑排除某些图像中的区域时,此参数可用,通过在FeatureComputation中对待进行np.stack的第五张图(mask)中进行排除区域标记(标记为0),然后在此处进行非0判断,以达到排除作用\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    ns = image[0].shape[-1]  # 传入处理后的subsample,维度信息:[channel,height,width,featureComputation中np.stack堆叠的特征图数量]\n",
    "    if weight:\n",
    "        vector = np.asarray([el[:, :, :, : -1][el[:, :, :, -1] != 0] for el in image], dtype=np.ndarray)  # 4d->2d,(34,512,512,4 -> 35651584)(事先未标记体素,非零排除不减少数据),用于排除mask中事先标记的需要排除的体素(voxel)\n",
    "    else:\n",
    "        vector = np.asarray([el.reshape(-1, ns) for el in image], dtype=np.ndarray)  # 4d->2d,(34,512,512,5 ->8912896,5)\n",
    "        \n",
    "    # 初始化质心和结果列表为空\n",
    "    centroid = []\n",
    "    ret = []\n",
    "        \n",
    "    from tqdm import tqdm\n",
    "    import cv2\n",
    "    for el in tqdm(vector):\n",
    "        r, _, centroids = cv2.kmeans(el.astype(np.float32),\n",
    "                                     K=n_centroids,\n",
    "                                     bestLabels=None,\n",
    "                                     criteria=stopping_criteria,\n",
    "                                     attempts=10,\n",
    "                                     flags=centroids_initiation)\n",
    "        centroid.append(centroids)\n",
    "        ret.append(r)\n",
    "    return [np.asarray(ret, dtype=np.float32), np.asarray(centroid, dtype=np.float32)]"
   ],
   "id": "5983695e4e0b531b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CTLungSeg.metrics\n",
    "## Overview\n",
    "这个名为`metric.py`的文件是一个Python模块，用于计算二进制图像的不同评估指标。让我逐个解释其中的内容：\n",
    "\n",
    "1. 导入了`numpy`库，用于数值计算。\n",
    "\n",
    "2. 定义了两个作者和邮箱的元数据。\n",
    "\n",
    "3. `__all__`列表定义了在导入模块时可以使用的公共函数。\n",
    "\n",
    "4. `precision`函数计算两个样本之间的精确度（Precision）分数，作为真正例和真正例与假正例之和的比率。每个样本必须是一个仅包含0和1值的二进制NumPy数组。`y_true`和`y_pred`必须具有相同的形状。函数返回精确度分数。\n",
    "\n",
    "5. `recall`函数计算两个样本之间的召回率（Recall）分数，作为真正例和真正例与假反例之和的比率。每个样本必须是一个仅包含0和1值的二进制NumPy数组。`y_true`和`y_pred`必须具有相同的形状。函数返回召回率分数。\n",
    "\n",
    "6. `dice`函数计算两个样本之间的Dice分数，作为真正例的两倍与真正例的两倍、假正例和假反例之和的比率。每个样本必须是一个仅包含0和1值的二进制NumPy数组。`y_true`和`y_pred`必须具有相同的形状。函数返回Dice分数。\n",
    "\n",
    "7. `specificity`函数计算两个样本之间的特异度（Specificity）分数，作为真反例和真反例与假正例之和的比率。每个样本必须是一个仅包含0和1值的二进制NumPy数组。`y_true`和`y_pred`必须具有相同的形状。函数返回特异度分数。\n",
    "\n",
    "8. `accuracy`函数计算两个样本之间的准确度（Accuracy）分数，作为真正例和真反例的总和与样本总数之间的比率。每个样本必须是一个仅包含0和1值的二进制NumPy数组。`y_true`和`y_pred`必须具有相同的形状。函数返回准确度分数。\n",
    "\n",
    "这个模块提供了一些常用的评估指标函数，可以用于计算二进制图像分割任务的性能评估。\n",
    "## Related Knowledge\n",
    "[评估指标](https://blog.csdn.net/qq_35218635/article/details/110001554)\n",
    "1. 二分类问题的结果划分\n",
    "\n",
    "    | 在预测的角度看真假 | 预测正例 | 预测反例 |\n",
    "    | ------------------ | -------- | -------- |\n",
    "    | 真实正例           | 真正例   | 假反例   |\n",
    "    | 真实反例           | 假正例   | 真反例   |\n",
    "\n",
    "1. F1-score\n",
    "   - 查准率Precision\n",
    "     - 预测正例中有多少真正例(一行)$\\frac{TP}{TP+FP}$\n",
    "   - 查全率Recall\n",
    "     - 真正正例中有多少被预测为正例(一列)$\\frac{TP}{TP+FN}$\n",
    "   - F1-score\n",
    "     - $\\frac{2PR}{P+R}$\n",
    "2. AUC\n",
    "   - 二分类任务给出概率(即回归),按概率排序,"
   ],
   "id": "f7ae1c91d58b6987"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "def precision(y_true, y_pred, eps=1e-9):\n",
    "    \"\"\"查准率(TP/(TP+FP))\"\"\"\n",
    "    # 要求y_true(真实值)和y_pred(预测值)形状需要相同\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise Exception(\"y_true's shape does not match the y_pred's shape,{} != {}\".format(y_true.shape, y_pred.shape))\n",
    "    \n",
    "    # 二值化,非零转化为1,0转为为0\n",
    "    y_true = (y_true != 0).astype(np.uint8)\n",
    "    y_pred = (y_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred)  # 计算真正例的数量，即被划分为正例的实际正例\n",
    "    fp = np.sum((1 - y_true) * y_pred)  # 计算假正例的数量，即被划分为正例的实际反例\n",
    "    return tp / (tp + fp + eps)  # 返回查准率(precision)：计算真正例与真正例和假正例之和的比率，加上一个很小的值 eps 以避免除以零的错误。\n",
    "\n",
    "def recall(y_true, y_pred, eps=1e-9):\n",
    "    \"\"\"查全率(TP/(TP+FN))\"\"\"\n",
    "    \n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise Exception(\"y_true's shape does not match the y_pred's shape,{} != {}\".format(y_true.shape, y_pred.shape))\n",
    "    \n",
    "    y_true = (y_true != 0).astype(np.uint8)\n",
    "    y_pred = (y_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred) \n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))  # 计算假反例的数量,即被划分为反例的真实正例\n",
    "    \n",
    "    return (2. * tp) / (2 * tp + fp + fn + eps)\n",
    "\n",
    "def dice(y_true, y_pred, eps=1e-9):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise Exception(\"y_true's shape does not match the y_pred's shape,{} != {}\".format(y_true.shape, y_pred.shape))\n",
    "    \n",
    "    y_true = (y_true != 0).astype(np.uint8)\n",
    "    y_pred = (y_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred) \n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    \n",
    "    return (2. * tp) / (2 * tp + fp + fn + eps)\n",
    "\n",
    "def specify(y_true, y_pred, eps=1e-9):\n",
    "    \"\"\"TN/(TN+FP)\"\"\"\n",
    "    \n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise Exception(\"y_true's shape does not match the y_pred's shape,{} != {}\".format(y_true.shape, y_pred.shape))\n",
    "    \n",
    "    y_true = (y_true != 0).astype(np.uint8)\n",
    "    y_pred = (y_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    tn = np.sum((1 - y_true) * (1- y_pred))\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    \n",
    "    return tn / (tn + fp + eps)\n",
    "\n",
    "def accuracy(y_true, y_pred, eps=1e-9):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise Exception(\"y_true's shape does not match the y_pred's shape,{} != {}\".format(y_true.shape, y_pred.shape))\n",
    "    \n",
    "    y_true = (y_true != 0).astype(np.uint8)\n",
    "    y_pred = (y_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    tn = np.sum((1 - y_true) * (1 - y_pred))\n",
    "    total = y_pred.size\n",
    "    \n",
    "    return (tp + tn) / total"
   ],
   "id": "7f2cf853778282b0",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
